# üöÄ Quick Start Guide - AI Chatbot Test

## üéâ LATEST UPDATE (Feb 16, 2026): Data-Driven Responses Implemented!

### ‚úÖ What Changed
**Previous Issue**: Chatbot was using hardcoded template responses instead of reading from knowledge base.

**Solution**: Complete refactor to **extract and use actual content** from retrieved documents.

### ‚ú® How It Works Now
1. **RAG Retrieves**: Searches 19+ documents, returns top 3 most relevant
2. **Content Extraction**: Analyzes document content, scores lines based on query keywords
3. **Intelligent Formatting**: Generates natural response from extracted content
4. **Result**: Every answer is **generated from actual knowledge base data**, not templates!

### üß™ Proof It's Data-Driven
**Test it yourself:**
```bash
cd Client
node test-chatbot.js
```
This will show you:
- Which documents RAG retrieves for each query
- The actual content from those documents (first 200 chars)
- How the response is generated from that content
- Confirmation that answers come from knowledge base

**Or use browser (F12 console):**
```
Visit: http://localhost:5174/participant/chatbot-test
Open console, you'll see:
üîç RAG Retrieved: {query: "...", docsFound: 3, topDocs: [...]}
üìÑ Using document: Registration (RAG score: 15)
```

---

## ‚úÖ What Was Implemented

A fully functional **RAG (Retrieval-Augmented Generation) + LLM** chatbot with:
- ‚úÖ Intelligent query understanding
- ‚úÖ Context-aware responses
- ‚úÖ Personalized answers using user data
- ‚úÖ Source citations
- ‚úÖ Suggested follow-up questions
- ‚úÖ Beautiful floating chat widget
- ‚úÖ Complete demo page with documentation

## üéØ How to Test

### Step 1: Start the Development Server

```bash
cd Client
npm run dev
```

The server will start on `http://localhost:5173` (or your configured port)

### Step 2: Navigate to Chatbot Test Page

**URL**: `/participant/chatbot-test`

**Full Path**: `http://localhost:5173/participant/chatbot-test`

> **Note**: You'll need to be logged in as a PARTICIPANT role. If you haven't set up authentication yet, you can temporarily modify the route protection in `App.jsx`.

### Step 3: Open the Chat Widget

Click the floating **purple chat button** in the bottom-right corner of the screen.

### Step 4: Try Sample Queries

**Start with a greeting:**
```
Hi!
```

**Ask about registration:**
```
How do I register for events?
```

**Ask personal questions:**
```
How many certificates do I have?
```

**Ask about specific events:**
```
Tell me about the React Workshop
```

**Ask about policies:**
```
What's the cancellation policy?
```

## üé® What You'll See

### Main Test Page Features:
1. **Welcome Section**: Overview of chatbot capabilities
2. **User Profile Context**: Shows dummy user data being used
3. **Sample Queries**: Pre-written questions organized by category
4. **Technical Details**: Expandable section showing implementation details
5. **Demo vs Production Comparison**: Side-by-side comparison table
6. **Floating Chat Button**: Animated button to open chat

### Chat Widget Features:
1. **Header**: Shows "Planix AI Assistant" with clear button
2. **Message Area**: Color-coded messages (blue=you, white=AI)
3. **Sources**: Shows which knowledge base sections were used
4. **Suggested Questions**: Quick-tap buttons for related queries
5. **Input Area**: Send messages with Enter key or button
6. **Loading Animation**: Bouncing dots while AI "thinks"

## üß™ Test Scenarios

### Scenario 1: General Knowledge
```
Query: "What types of events are available?"

Expected: Lists 6 event types (Workshop, Seminar, Hackathon, etc.)
with brief descriptions
```

### Scenario 2: Personal Data
```
Query: "How many events have I attended?"

Expected: Shows your attendance history from dummy user data
(2 recent events listed)
```

### Scenario 3: Certificates
```
Query: "When will I receive my certificate?"

Expected: Explains 7-10 day timeline, eligibility criteria,
and how to download
```

### Scenario 4: Multi-turn Conversation
```
Query 1: "How do I register?"
Response: Registration steps...

Query 2: "Can I cancel?"
Response: Cancellation policy... (maintains context)
```

## üîç How the AI Works (Behind the Scenes)

### Query Flow:
```
User: "How many certificates do I have?"
  ‚Üì
1. Preprocessing: "how many certificates do i have"
  ‚Üì
2. RAG Retrieval: 
   - Searches knowledge base
   - Finds: rulebook (certificate section), FAQ (certificate info)
   - Detects personal query ‚Üí also fetches user data
  ‚Üì
3. Context Building:
   Knowledge: "Certificates issued within 7-10 days..."
   User Data: "2 certificates (Python Workshop, Git Session)"
  ‚Üì
4. LLM Generation:
   Selects "personal_certificate_count" template
   Fills with user data
  ‚Üì
5. Response: "You have 2 certificates: 1. Python Workshop..."
```

### Similarity Scoring Example:
```
Query: "certificate requirements"

Document Scores:
- Rulebook: Certificates ‚Üí 18 points
  (keyword: "certificate" = 5, "requirements" = 5, section match = 3)
  
- FAQ: Certificate timing ‚Üí 10 points
  (keyword: "certificate" = 5)
  
- Rulebook: Registration ‚Üí 2 points
  (no strong matches)

Top 3 Retrieved:
1. Rulebook: Certificates (18)
2. FAQ: Certificate timing (10)
3. FAQ: Certificate downloads (8)
```

## üìä Knowledge Base Coverage

### Topics the AI Can Answer:
‚úÖ Registration process (how to register, requirements)
‚úÖ Cancellation policy (deadlines, refunds)
‚úÖ Attendance marking (QR codes, manual check-in)
‚úÖ Certificate eligibility (requirements, timeline)
‚úÖ Event types (workshops, seminars, hackathons, etc.)
‚úÖ Personal history (your registrations, certificates, attendance)
‚úÖ Contact information (support email, phone)
‚úÖ Technical requirements (software, internet, devices)
‚úÖ Code of conduct (rules, behavior guidelines)

### What It CAN'T Answer (Current Limitations):
‚ùå Real-time event availability
‚ùå Specific dates not in dummy data
‚ùå Other users' information
‚ùå Complex calculations beyond the data
‚ùå Queries requiring external data

## üéØ Expected Response Quality

### High Quality Responses (90%+ accuracy):
- Registration process
- Certificate requirements
- Attendance procedures
- Event types
- Personal data queries
- Policy questions

### Medium Quality Responses (70-85% accuracy):
- Specific event details (limited to 4 dummy events)
- Edge case scenarios
- Very specific technical questions

### Low Quality Responses (<70% accuracy):
- Questions outside knowledge base
- Queries about future changes
- Complex multi-step processes not documented

## üêõ Troubleshooting

### Chat Widget Not Opening
**Issue**: Button clicks but nothing happens
**Fix**: Check browser console for errors. Ensure all imports are correct.

### Slow Responses
**Issue**: Takes >2 seconds to respond
**Fix**: This is simulated delay (800-1200ms). Check if there are actual errors in console.

### No User Data in Responses
**Issue**: Personal queries don't show user information
**Fix**: Check `knowledgeBase.js` ‚Üí `dummyUserData` is properly exported.

### RAG Not Finding Documents
**Issue**: Response says "I don't have information..."
**Fix**: Check if keywords in your query match those in `knowledgeBase.js`. Try different phrasing.

### Blank Messages
**Issue**: Empty messages in chat
**Fix**: Ensure `llmSimulation.js` response function returns non-empty strings.

## üîß Customization Tips

### Add New Knowledge:
Edit `Client/src/pages/chatbot-test/knowledgeBase.js`:

```javascript
// Add to rulebook array
rulebook.push({
  id: 'rule_009',
  section: 'Feedback',
  content: 'How to provide event feedback...',
  keywords: ['feedback', 'review', 'rating', 'survey']
});
```

### Change User Context:
Edit `dummyUserData` in `knowledgeBase.js`:

```javascript
export const dummyUserData = {
  name: 'Your Name',
  certificates: [...],
  // ... modify as needed
};
```

### Adjust Response Style:
Edit templates in `Client/src/utils/llmSimulation.js`:

Look for functions like `generatePersonalResponse()` and modify the return strings.

## üì± Mobile Testing

The chat widget is responsive! Test on mobile:
1. Open Chrome DevTools (F12)
2. Click "Toggle device toolbar" (Ctrl+Shift+M)
3. Select a mobile device (iPhone, Pixel)
4. Test chat functionality

## üéì Learning Resources

### Understanding RAG:
- Our implementation: `Client/src/utils/ragSimulation.js`
- Read the comments explaining each step

### Understanding LLM Prompting:
- Our templates: `Client/src/utils/llmSimulation.js`
- See how context is injected into responses

### React Chat UI Patterns:
- Our widget: `Client/src/components/ChatWidget.jsx`
- Clean, reusable component structure

## üöÄ Next Steps

### For Development:
1. ‚úÖ Test with various queries
2. ‚úÖ Get user feedback
3. ‚úÖ Identify gaps in knowledge base
4. ‚è≥ Prepare for backend integration
5. ‚è≥ Set up OpenAI API keys
6. ‚è≥ Deploy ChromaDB vector store

### For Production:
1. Replace simulated RAG with real embeddings
2. Replace simulated LLM with GPT-4/Gemini API
3. Connect to MongoDB for user data
4. Add chat history persistence
5. Implement feedback system
6. Add analytics dashboard

## üìß Support

**Questions about implementation?**
- Check `README.md` in the chatbot-test folder
- Review inline code comments
- Test queries in the demo page

**Need help with integration?**
- Backend integration guide in `README.md`
- API endpoint specifications included
- Database schema examples provided

---

**Status**: ‚úÖ Ready for Testing  
**Estimated Test Time**: 10-15 minutes  
**Recommended Testers**: Developers, Product Team, Sample Users

Enjoy testing the AI chatbot! ü§ñ‚ú®
